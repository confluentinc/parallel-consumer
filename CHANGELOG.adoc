:toc: macro
:toclevels: 1

= Change Log

toc::[]

== v0.3.0.0

== next

=== Features
* Queueing and pressure system now self tuning, performance over default old tuning values (`softMaxNumberMessagesBeyondBaseCommitOffset` and `maxMessagesToQueue`) has doubled.
** These options have been removed from the system.

=== Improvements
* Default ordering mode is now `KEY` ordering (was `UNORDERED`).
** This is a better default as it's the safest mode yet high performing mode.
It maintains the partition ordering characteristic that all keys are processed in log order, yet for most use cases will be close to as fast as `UNORDERED` when the key space is large enough.
* https://github.com/confluentinc/parallel-consumer/issues/37[Support BitSet encoding lengths longer than Short.MAX_VALUE #37] - adds new serialisation formats that supports wider range of offsets - (32,767 vs  2,147,483,647) for both BitSet and run-length encoding.
* Commit modes have been renamed to make it clearer that they are periodic, not per message.
* Minor performance improvement, switching away from concurrent collections.

=== Fixes
* Maximum offset payload space increased to correctly not be inversely proportional to assigned partition quantity.
* Run-length encoding now supports compacted topics, plus other bug fixes.

== v0.2.0.3

=== Fixes
** https://github.com/confluentinc/parallel-consumer/issues/35[Bitset overflow check (#35)] - gracefully drop BitSet or Runlength encoding as an option if offset difference too large (short overflow)
*** A new serialisation format will be added in next version - see https://github.com/confluentinc/parallel-consumer/issues/37[Support BitSet encoding lengths longer than Short.MAX_VALUE #37]
** Gracefully drops encoding attempts if they can't be run
** Fixes a bug in the offset drop if it can't fit in the offset metadata payload

== v0.2.0.2

=== Fixes
** Turns back on the https://github.com/confluentinc/parallel-consumer/issues/35[Bitset overflow check (#35)]

== v0.2.0.1 DO NOT USE - has critical bug

=== Fixes
** Incorrectly turns off an over-flow check in https://github.com/confluentinc/parallel-consumer/issues/35[offset serialisation system (#35)]

== v0.2.0.0

=== Features
** Choice of commit modes: Consumer Asynchronous, Synchronous and Producer Transactions
** Producer instance is now optional
** Using a _transactional_ Producer is now optional
** Use the Kafka Consumer to commit `offsets` Synchronously or Asynchronously

=== Improvements
** Memory performance - garbage collect empty shards when in KEY ordering mode
** Select tests adapted to non transactional (multiple commit modes) as well
** Adds supervision to broker poller
** Fixes a performance issue with the async committer not being woken up
** Make committer thread revoke partitions and commit
** Have onPartitionsRevoked be responsible for committing on close, instead of an explicit call to commit by controller
** Make sure Broker Poller now drains properly, committing any waiting work

=== Fixes
** Fixes bug in commit linger, remove genesis offset (0) from testing (avoid races), add ability to request commit
** Fixes #25 https://github.com/confluentinc/parallel-consumer/issues/25:
*** Sometimes a transaction error occurs - Cannot call send in state COMMITTING_TRANSACTION #25
** ReentrantReadWrite lock protects non-thread safe transactional producer from incorrect multithreaded use
** Wider lock to prevent transaction's containing produced messages that they shouldn't
** Must start tx in MockProducer as well
** Fixes example app tests - incorrectly testing wrong thing and MockProducer not configured to auto complete
** Add missing revoke flow to MockConsumer wrapper
** Add missing latch timeout check

== v0.1

=== Features:
** Have massively parallel consumption processing without running hundreds or thousands of
*** Kafka consumer clients
*** topic partitions
+
without operational burden or harming the clusters performance
** Efficient individual message acknowledgement system (without local or third system state) to massively reduce message replay upon failure
** Per `key` concurrent processing, per `partition` and unordered message processing
** `Offsets` committed correctly, in order, of only processed messages, regardless of concurrency level or retries
** Vert.x non-blocking library integration (HTTP currently)
** Fair partition traversal
** Zero~ dependencies (`Slf4j` and `Lombok`) for the core module
** Java 8 compatibility
** Throttle control and broker liveliness management
** Clean draining shutdown cycle
