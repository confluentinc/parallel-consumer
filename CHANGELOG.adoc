= Change Log

== v0.3.0.0

* Fixes
** https://github.com/confluentinc/parallel-consumer/issues/37[Support BitSet encoding lengths longer than Short.MAX_VALUE #37] - adds new serialisation formats that supports wider range of offsets - (32,767 vs  2,147,483,647) for both BitSet and run-length encoding

== v0.2.0.3

* Fixes
** https://github.com/confluentinc/parallel-consumer/issues/35[Bitset overflow check (#35)] - gracefully drop BitSet or Runlength encoding as an option if offset difference too large (short overflow)
*** A new serialisation format will be added in next version - see https://github.com/confluentinc/parallel-consumer/issues/37[Support BitSet encoding lengths longer than Short.MAX_VALUE #37]
** Gracefully drops encoding attempts if they can't be run
** Fixes a bug in the offset drop if it can't fit in the offset metadata payload

== v0.2.0.2

* Fixes
** Turns back on the https://github.com/confluentinc/parallel-consumer/issues/35[Bitset overflow check (#35)]

== v0.2.0.1 DO NOT USE - has critical bug

* Fixes
** Incorrectly turns off an over-flow check in https://github.com/confluentinc/parallel-consumer/issues/35[offset serialisation system (#35)]

== v0.2.0.0

* Features:
** Choice of commit modes: Consumer Asynchronous, Synchronous and Producer Transactions
** Producer instance is now optional
** Using a _transactional_ Producer is now optional
** Use the Kafka Consumer to commit `offsets` Synchronously or Asynchronously

* Improvements:
** Memory performance - garbage collect empty shards when in KEY ordering mode
** Select tests adapted to non transactional (multiple commit modes) as well
** Adds supervision to broker poller
** Fixes a performance issue with the async committer not being woken up
** Make committer thread revoke partitions and commit
** Have onPartitionsRevoked be responsible for committing on close, instead of an explicit call to commit by controller
** Make sure Broker Poller now drains properly, committing any waiting work

* Fixes:
** Fixes bug in commit linger, remove genesis offset (0) from testing (avoid races), add ability to request commit
** Fixes #25 https://github.com/confluentinc/parallel-consumer/issues/25:
*** Sometimes a transaction error occurs - Cannot call send in state COMMITTING_TRANSACTION #25
** ReentrantReadWrite lock protects non-thread safe transactional producer from incorrect multithreaded use
** Wider lock to prevent transaction's containing produced messages that they shouldn't
** Must start tx in MockProducer as well
** Fixes example app tests - incorrectly testing wrong thing and MockProducer not configured to auto complete
** Add missing revoke flow to MockConsumer wrapper
** Add missing latch timeout check

== v0.1

* Features:
** Have massively parallel consumption processing without running hundreds or thousands of
*** Kafka consumer clients
*** topic partitions
+
without operational burden or harming the clusters performance
** Efficient individual message acknowledgement system (without local or third system state) to massively reduce message replay upon failure
** Per `key` concurrent processing, per `partition` and unordered message processing
** `Offsets` committed correctly, in order, of only processed messages, regardless of concurrency level or retries
** Vert.x non-blocking library integration (HTTP currently)
** Fair partition traversal
** Zero~ dependencies (`Slf4j` and `Lombok`) for the core module
** Java 8 compatibility
** Throttle control and broker liveliness management
** Clean draining shutdown cycle
