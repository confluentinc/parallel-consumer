# Parallel Consumer Metrics

This document is intended to gather a few initial metrics that can be used to monitor the performance and health of the parallel consumer.

## Meters
Following is meters defined by Parallel Consumer - grouped by Subsystem

### Partition Manager

**Number Of Partitions**

Gauge `pc.partitions.number{subsystem=partitions}`

Number of partitions

**Partition Incomplete Offsets**

Gauge `pc.partition.incomplete.offsets{subsystem=partitions, topic="topicName", partition="partitionNumber"}`

Number of incomplete offsets in the partition

**Partition Highest Completed Offset**

Gauge `pc.partition.highest.completed.offset{subsystem=partitions, topic="topicName", partition="partitionNumber"}`

Highest completed offset in the partition

**Partition Highest Sequential Succeeded Offset**

Gauge `pc.partition.highest.sequential.succeeded.offset{subsystem=partitions, topic="topicName", partition="partitionNumber"}`

Highest sequential succeeded offset in the partition

**Partition Highest Seen Offset**

Gauge `pc.partition.highest.seen.offset{subsystem=partitions, topic="topicName", partition="partitionNumber"}`

Highest seen / consumed offset in the partition

**Partition Last Committed Offset**

Gauge `pc.partition.latest.committed.offset{subsystem=partitions, topic="topicName", partition="partitionNumber"}`

Latest committed offset in the partition

**Partition Assignment Epoch**

Gauge `pc.partition.assignment.epoch{subsystem=partitions, topic="topicName", partition="partitionNumber"}`

Epoch of partition assignment

### Processor

**User Function Processing Time**

Timer `pc.user.function.processing.time{subsystem=processor}`

User function processing time

**Dynamic Extra Load Factor**

Gauge `pc.dynamic.load.factor{subsystem=processor}`

Dynamic load factor - load of processing buffers

### Shard Manager

**Number Of Shards**

Gauge `pc.shards{subsystem=shardmanager}`

Number of shards

**Incomplete Offsets Total**

Gauge `pc.incomplete.offsets.total{subsystem=shardmanager}`

Total number of incomplete offsets

**Shards Size**

Gauge `pc.shards.size{subsystem=shardmanager}`

Number of records queued for processing across all shards

### Work Manager

**Inflight Records**

Gauge `pc.inflight.records{subsystem=workmanager}`

Total number of records currently being processed or waiting for retry

**Waiting Records**

Gauge `pc.waiting.records{subsystem=workmanager}`

Total number of records waiting to be selected for processing

**Processed Records**

Counter `pc.processed.records{subsystem=workmanager, topic="topicName", partition="partitionNumber"}`

Total number of records successfully processed

**Failed Records**

Counter `pc.failed.records{subsystem=workmanager, topic="topicName", partition="partitionNumber"}`

Total number of records failed to be processed

**Slow Records**

Counter `pc.slow.records{subsystem=workmanager, topic="topicName", partition="partitionNumber"}`

Total number of records that spent more than the configured time threshold in the waiting queue. This setting defaults to 10 seconds

### Broker Poller

**Pc Status**

Gauge `pc.status{subsystem=poller, status="running|closing|closed|draining|paused|closed"}`

PC Status

**Num Paused Partitions**

Gauge `pc.partitions.paused{subsystem=poller}`

Number of paused partitions

### Offset Encoder

**Offsets Encoding Time**

Timer `pc.offsets.encoding.time{subsystem=offsetencoder}`

Time spend encoding offsets

**Offsets Encoding Usage**

Counter `pc.offsets.encoding.usage{subsystem=offsetencoder, codec="BitSet|BitSetCompressed|BitSetV2Compressed|RunLength"}`

Offset encoding usage per encoding type

**Metadata Space Used**

Distribution Summary `pc.metadata.space.used{subsystem=offsetencoder}`

Ratio between offset metadata payload size and available space

**Payload Ratio Used**

Distribution Summary `pc.payload.ratio.used{subsystem=offsetencoder}`

Ratio between offset metadata payload size and offsets encoded



## Example setup steps
Meter registry that metrics should be bound has to be set using Parallel Consumer Options along with any common tags that identify the PC instance.
In addition if desired - KafkaConsumer, Producer can be bound to the registry as well as general JVM level binders.
Following example illustrates setup of Parallel Consumer with Meter Registry and binds Kafka Consumer to that same registry as well.
`parallel-consumer-examples/parallel-consumer-example-metrics/src/main/java/io/confluent/parallelconsumer/examples/core/CoreApp.java`
[source,java,indent=0]
----
    ParallelStreamProcessor<String, String> setupParallelConsumer() {
        Consumer<String, String> kafkaConsumer = getKafkaConsumer();
        kafkaClientMetrics = new KafkaClientMetrics(kafkaConsumer); //<1>
        kafkaClientMetrics.bindTo(meterRegistry);                   //<2>

        var options = ParallelConsumerOptions.<String, String>builder()
                .ordering(ParallelConsumerOptions.ProcessingOrder.KEY)
                .maxConcurrency(1000)
                .consumer(kafkaConsumer)
                .meterRegistry(meterRegistry)                       //<3>
                .metricsTags(Tags.of(Tag.of("instance", "pc1")))    //<4>
                .build();

        ParallelStreamProcessor<String, String> eosStreamProcessor =
                ParallelStreamProcessor.createEosStreamProcessor(options);

        eosStreamProcessor.subscribe(of(inputTopic));


        return eosStreamProcessor;
    }
----
- (1) - Optional - Kafka Consumer Micrometer metrics object created for Kafka Consumer that is later used for Parallel Consumer.
- (2) - Optional - Kafka Consumer Micrometer metrics are bound to Meter Registry.
- (3) - Meter Registry is set through ParallelConsumerOptions.builder(), if not specified - will default to CompositeMeterRegistry - which is No-op.
- (4) - Optional - "instance" tag with value of "pc1" is set through same builder - it will be added to all Parallel Consumer meters

NOTE:: any additional binders / metrics need to be cleaned up appropriately - for example the Kafka Consumer Metrics registered above - need to be closed using `kafkaClientMetrics.close()` after calling shutting down Parallel Consumer as Parallel Consumer will close Kafka Consumer on shutdown.

